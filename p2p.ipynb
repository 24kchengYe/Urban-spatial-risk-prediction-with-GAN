{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p2p.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdgVvpwk3vQn",
        "colab_type": "code",
        "outputId": "e75f4b8e-6d6f-4794-cfbe-a7274f1dc67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun  7 03:50:49 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6bmX0e7T2rM",
        "colab_type": "code",
        "outputId": "d451dd6c-7221-4cd6-b268-3e39722e0da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "%tensorflow_version 1.12.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.12.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGVe8ITnt-eI",
        "colab_type": "code",
        "outputId": "4c2668c8-2641-4462-d04c-539a23227b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip uninstall -y mkl\n",
        "!pip install --upgrade mxnet\n",
        "!pip install autogluon\n",
        "!pip install torch==0.4.0\n",
        "!pip install torchvision==0.2.2\n",
        "!pip install Pillow==6.2.2\n",
        "!pip install dominate\n",
        "!pip install scipy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling mkl-2019.0:\n",
            "  Successfully uninstalled mkl-2019.0\n",
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/f5/d79b5b40735086ff1100c680703e0f3efc830fa455e268e9e96f3c857e93/mxnet-1.6.0-py2.py3-none-any.whl (68.7MB)\n",
            "\u001b[K     |████████████████████████████████| 68.7MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.18.4)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.6.0\n",
            "Collecting autogluon\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/e3/5b9f02d217567b1831fb7c7bcd45410a94c6e759fa18ec41b40f725647aa/autogluon-0.0.10-py3-none-any.whl (388kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (4.41.1)\n",
            "Collecting distributed>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/41/faf6df58e4e7955622266682334357870b7712483b85b96dfe8f18183f55/distributed-2.18.0-py3-none-any.whl (640kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 14.3MB/s \n",
            "\u001b[?25hCollecting tornado>=5.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/84/119a46d494f008969bf0c775cb2c6b3579d3c4cc1bb1b41a022aa93ee242/tornado-6.0.4.tar.gz (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from autogluon) (0.8.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from autogluon) (1.13.19)\n",
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/87/310b52debfbc0cb79764e5770fa3f5c18f6f0754809ea9e2fc185e1b67d3/scikit_optimize-0.7.4-py2.py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from autogluon) (0.29.19)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (1.18.4)\n",
            "Requirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (2.12.0)\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/04/686efee2dcdd25aecf357992e7d9362f443eb182ecd623f882bc9f7a6bba/cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 41.6MB/s \n",
            "\u001b[?25hCollecting paramiko>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/1e/1e08baaaf6c3d3df1459fd85f0e7d2d6aa916f33958f151ee1ecc9800971/paramiko-2.7.1-py2.py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from autogluon) (2.23.0)\n",
            "Collecting pandas<1.0,>=0.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 43.9MB/s \n",
            "\u001b[?25hCollecting ConfigSpace<=0.4.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/de/4e8e4f26332fc65404f52baa112defbf822b6738b60bfa6b2993f5c60933/ConfigSpace-0.4.10.tar.gz (882kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 38.0MB/s \n",
            "\u001b[?25hCollecting Pillow<=6.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5c/0e94e689de2476c4c5e644a3bd223a1c1b9e2bdb7c510191750be74fa786/Pillow-6.2.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<0.23,>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from autogluon) (1.4.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from autogluon) (5.4.8)\n",
            "Collecting gluonnlp==0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/2d/40c2ad37d74e5e9030064d73542b7df0f7df7ba98d47932874033cf03d79/gluonnlp-0.8.1.tar.gz (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 44.9MB/s \n",
            "\u001b[?25hCollecting catboost<0.24\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/aa/e61819d04ef2bbee778bf4b3a748db1f3ad23512377e43ecfdc3211437a0/catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8MB)\n",
            "\u001b[K     |████████████████████████████████| 64.8MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from autogluon) (3.2.1)\n",
            "Requirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.6/dist-packages (from autogluon) (2.4)\n",
            "Collecting gluoncv<1.0,>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/81/37a00609cb53da3671adb106b9bc03fb1c029ad5a8db4bc668283e65703d/gluoncv-0.7.0-py2.py3-none-any.whl (752kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 41.0MB/s \n",
            "\u001b[?25hCollecting lightgbm<3.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from autogluon) (3.6.4)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (0.10.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (3.13)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (2.0.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (2.1.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (1.6.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (47.1.1)\n",
            "Collecting contextvars; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Requirement already satisfied: cloudpickle>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.6.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->autogluon) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.19 in /usr/local/lib/python3.6/dist-packages (from boto3->autogluon) (1.16.19)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->autogluon) (0.3.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize->autogluon) (0.15.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->autogluon) (1.14.0)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->autogluon) (1.12.0)\n",
            "Collecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/1d/82826443777dd4a624e38a08957b975e75df859b381ae302cfd7a30783ed/bcrypt-3.1.7-cp34-abi3-manylinux1_x86_64.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 40.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->autogluon) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->autogluon) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->autogluon) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->autogluon) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas<1.0,>=0.24.0->autogluon) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas<1.0,>=0.24.0->autogluon) (2.8.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<=0.4.10->autogluon) (2.4.7)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<=0.4.10->autogluon) (3.6.6)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost<0.24->autogluon) (4.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->autogluon) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->autogluon) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx<3.0,>=2.3->autogluon) (4.4.2)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->autogluon) (8.3.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->autogluon) (19.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->autogluon) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->autogluon) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->autogluon) (1.8.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.6/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon) (1.0.1)\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.19->boto3->autogluon) (0.15.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->autogluon) (2.20)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost<0.24->autogluon) (1.3.3)\n",
            "Building wheels for collected packages: tornado, ConfigSpace, gluonnlp, contextvars\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-6.0.4-cp36-cp36m-linux_x86_64.whl size=427640 sha256=741421de773e72d0c4172d9c4ba561e0109b63cfd13118074035ef875ca82b33\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/84/2f/409c7b2bb3afc3aa727f7ee8787975e0793f74d1165f4d0104\n",
            "  Building wheel for ConfigSpace (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.10-cp36-cp36m-linux_x86_64.whl size=2712232 sha256=ea6f3546f7710332825a527c68a7d9c7904d5dbeb91d13ba67fda7b12d91ca20\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/83/cb/28dd42bac69c8867d485138030daa83841c7f84afe68b2fdf7\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.8.1-cp36-none-any.whl size=293521 sha256=edf1a2b023ba587596b7660ff5819b8746c7a3f886837a8993a3fa7cfa556d88\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/e7/3e/9cdf8ad7fce112fde2f4a52604045e5dd80f84d645bedb70c7\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=6faec461a26ae32aa628e0eb9a4acae50735f81e9d5b53c0daa70750135383a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built tornado ConfigSpace gluonnlp contextvars\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tornado, immutables, contextvars, distributed, pyaml, scikit-optimize, cryptography, bcrypt, pynacl, paramiko, pandas, ConfigSpace, Pillow, gluonnlp, catboost, portalocker, gluoncv, lightgbm, autogluon\n",
            "  Found existing installation: tornado 4.5.3\n",
            "    Uninstalling tornado-4.5.3:\n",
            "      Successfully uninstalled tornado-4.5.3\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Found existing installation: pandas 1.0.4\n",
            "    Uninstalling pandas-1.0.4:\n",
            "      Successfully uninstalled pandas-1.0.4\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed ConfigSpace-0.4.10 Pillow-6.2.1 autogluon-0.0.10 bcrypt-3.1.7 catboost-0.23.2 contextvars-2.4 cryptography-2.9.2 distributed-2.18.0 gluoncv-0.7.0 gluonnlp-0.8.1 immutables-0.14 lightgbm-2.3.1 pandas-0.25.3 paramiko-2.7.1 portalocker-1.7.0 pyaml-20.4.0 pynacl-1.4.0 scikit-optimize-0.7.4 tornado-6.0.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pandas",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n",
            "\u001b[K     |████████████████████████████████| 484.0MB 31kB/s \n",
            "\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "Successfully installed torch-0.4.0\n",
            "Collecting torchvision==0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/a1/66d72a2fe580a9f0fcbaaa5b976911fbbde9dce9b330ba12791997b856e9/torchvision-0.2.2-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (0.4.0)\n",
            "Collecting tqdm==4.19.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/c4/b67cf1ab472b770e08e94105a0c7ca7032cd070627c435f5998c9cf6e64f/tqdm-4.19.9-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (6.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (1.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (1.12.0)\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.19.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: autogluon 0.0.10 has requirement tqdm>=4.38.0, but you'll have tqdm 4.19.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tqdm, torchvision\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: torchvision 0.6.0+cu101\n",
            "    Uninstalling torchvision-0.6.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Successfully installed torchvision-0.2.2 tqdm-4.19.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==6.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.4MB/s \n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: autogluon 0.0.10 has requirement Pillow<=6.2.1, but you'll have pillow 6.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: autogluon 0.0.10 has requirement tqdm>=4.38.0, but you'll have tqdm 4.19.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Found existing installation: Pillow 6.2.1\n",
            "    Uninstalling Pillow-6.2.1:\n",
            "      Successfully uninstalled Pillow-6.2.1\n",
            "Successfully installed Pillow-6.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/e6/794a119963b7cfe4bd41177c8f9d4195fe901652f04189fbd2edf513c7b2/dominate-2.5.1-py2.py3-none-any.whl\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.5.1\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLfgbou2GJY7",
        "colab_type": "code",
        "outputId": "2bc0de0f-6414-405e-a93f-c76bb5867c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/pix2pixHD\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['precompute_feature_maps.py',\n",
              " 'encode_features.py',\n",
              " 'frame.txt',\n",
              " 'lm.py',\n",
              " 'test.py',\n",
              " 'train.py',\n",
              " 'CM.txt',\n",
              " 'options',\n",
              " 'datasets',\n",
              " 'scripts',\n",
              " 'util',\n",
              " 'models',\n",
              " 'data',\n",
              " 'checkpoints',\n",
              " 'p2p.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6_mb3BTSg1_",
        "colab_type": "code",
        "outputId": "dcb0986f-cca9-4671-eaa3-0724a1ae8ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%run train.py --name force --dataroot ./datasets/force/ --no_instance --label_nc 0 --loadSize 1024 --fineSize 1024 --resize_or_crop none --niter 140 --niter_decay 60 --save_epoch_freq 20 --no_flip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 1\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: False\n",
            "dataroot: ./datasets/force/\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 1024\n",
            "gpu_ids: [0]\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: force\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 140\n",
            "niter_decay: 60\n",
            "niter_fix_global: 0\n",
            "no_flip: True\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: True\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "resize_or_crop: none\n",
            "save_epoch_freq: 20\n",
            "save_latest_freq: 1000\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "#training images = 21\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "MultiscaleDiscriminator(\n",
            "  (scale0_layer0): Sequential(\n",
            "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
            "  )\n",
            "  (scale0_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
            "  )\n",
            "  (scale0_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
            "  )\n",
            "  (scale0_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
            "  )\n",
            "  (scale0_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (scale1_layer0): Sequential(\n",
            "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
            "  )\n",
            "  (scale1_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
            "  )\n",
            "  (scale1_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
            "  )\n",
            "  (scale1_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
            "  )\n",
            "  (scale1_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "---------- Networks initialized -------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.torch/models/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 574673361/574673361 [00:12<00:00, 43008853.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model [Pix2PixHDModel] was created\n",
            "create web directory ./checkpoints/force/web...\n",
            "End of epoch 1 / 200 \t Time Taken: 20 sec\n",
            "End of epoch 2 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 3 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 4 / 200 \t Time Taken: 19 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/pix2pixHD/train.py:83: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  errors = {k: v.data[0] if not isinstance(v, int) else v for k, v in loss_dict.items()}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(epoch: 5, iters: 16, time: 0.916) G_GAN: 1.682 G_GAN_Feat: 7.462 G_VGG: 4.461 D_real: 0.577 D_fake: 0.344 \n",
            "End of epoch 5 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 6 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 7 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 8 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 9 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 10, iters: 11, time: 0.916) G_GAN: 0.623 G_GAN_Feat: 3.416 G_VGG: 4.394 D_real: 0.408 D_fake: 0.514 \n",
            "End of epoch 10 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 11 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 12 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 13 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 14 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 15, iters: 6, time: 0.916) G_GAN: 1.338 G_GAN_Feat: 4.661 G_VGG: 5.565 D_real: 0.447 D_fake: 0.219 \n",
            "End of epoch 15 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 16 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 17 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 18 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 19 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 20, iters: 1, time: 0.903) G_GAN: 1.105 G_GAN_Feat: 5.487 G_VGG: 4.801 D_real: 0.457 D_fake: 0.263 \n",
            "End of epoch 20 / 200 \t Time Taken: 19 sec\n",
            "saving the model at the end of epoch 20, iters 420\n",
            "End of epoch 21 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 22 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 23 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 24, iters: 17, time: 0.917) G_GAN: 0.974 G_GAN_Feat: 5.026 G_VGG: 5.242 D_real: 0.231 D_fake: 0.291 \n",
            "End of epoch 24 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 25 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 26 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 27 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 28 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 29, iters: 12, time: 0.910) G_GAN: 1.431 G_GAN_Feat: 4.630 G_VGG: 4.996 D_real: 0.539 D_fake: 0.168 \n",
            "End of epoch 29 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 30 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 31 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 32 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 33 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 34, iters: 7, time: 0.916) G_GAN: 1.739 G_GAN_Feat: 3.853 G_VGG: 4.076 D_real: 1.477 D_fake: 2.159 \n",
            "End of epoch 34 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 35 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 36 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 37 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 38 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 39, iters: 2, time: 0.918) G_GAN: 0.826 G_GAN_Feat: 4.749 G_VGG: 4.774 D_real: 0.395 D_fake: 0.375 \n",
            "End of epoch 39 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 40 / 200 \t Time Taken: 19 sec\n",
            "saving the model at the end of epoch 40, iters 840\n",
            "End of epoch 41 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 42 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 43, iters: 18, time: 0.917) G_GAN: 0.744 G_GAN_Feat: 4.199 G_VGG: 4.911 D_real: 0.254 D_fake: 0.487 \n",
            "End of epoch 43 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 44 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 45 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 46 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 47 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 48, iters: 13, time: 0.915) G_GAN: 0.928 G_GAN_Feat: 4.161 G_VGG: 4.582 D_real: 0.513 D_fake: 0.851 \n",
            "saving the latest model (epoch 48, total_steps 1000)\n",
            "End of epoch 48 / 200 \t Time Taken: 24 sec\n",
            "End of epoch 49 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 50 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 51 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 52 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 53, iters: 8, time: 0.915) G_GAN: 0.831 G_GAN_Feat: 5.105 G_VGG: 6.116 D_real: 0.159 D_fake: 0.425 \n",
            "End of epoch 53 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 54 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 55 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 56 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 57 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 58, iters: 3, time: 0.918) G_GAN: 0.694 G_GAN_Feat: 4.881 G_VGG: 5.483 D_real: 0.230 D_fake: 0.469 \n",
            "End of epoch 58 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 59 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 60 / 200 \t Time Taken: 19 sec\n",
            "saving the model at the end of epoch 60, iters 1260\n",
            "End of epoch 61 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 62, iters: 19, time: 0.918) G_GAN: 0.769 G_GAN_Feat: 2.958 G_VGG: 4.163 D_real: 0.429 D_fake: 0.362 \n",
            "End of epoch 62 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 63 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 64 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 65 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 66 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 67, iters: 14, time: 0.914) G_GAN: 0.661 G_GAN_Feat: 3.209 G_VGG: 3.964 D_real: 0.450 D_fake: 0.453 \n",
            "End of epoch 67 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 68 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 69 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 70 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 71 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 72, iters: 9, time: 0.916) G_GAN: 1.312 G_GAN_Feat: 4.534 G_VGG: 5.893 D_real: 0.714 D_fake: 0.209 \n",
            "End of epoch 72 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 73 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 74 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 75 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 76 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 77, iters: 4, time: 0.920) G_GAN: 0.547 G_GAN_Feat: 4.455 G_VGG: 6.281 D_real: 0.170 D_fake: 0.516 \n",
            "End of epoch 77 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 78 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 79 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 80 / 200 \t Time Taken: 19 sec\n",
            "saving the model at the end of epoch 80, iters 1680\n",
            "(epoch: 81, iters: 20, time: 0.916) G_GAN: 0.518 G_GAN_Feat: 4.060 G_VGG: 5.779 D_real: 0.207 D_fake: 0.649 \n",
            "End of epoch 81 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 82 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 83 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 84 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 85 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 86, iters: 15, time: 0.917) G_GAN: 0.747 G_GAN_Feat: 4.184 G_VGG: 5.762 D_real: 0.369 D_fake: 0.390 \n",
            "End of epoch 86 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 87 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 88 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 89 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 90 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 91, iters: 10, time: 0.917) G_GAN: 1.091 G_GAN_Feat: 2.691 G_VGG: 3.411 D_real: 0.797 D_fake: 0.773 \n",
            "End of epoch 91 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 92 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 93 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 94 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 95 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 96, iters: 5, time: 0.916) G_GAN: 0.347 G_GAN_Feat: 3.193 G_VGG: 3.968 D_real: 0.226 D_fake: 0.780 \n",
            "saving the latest model (epoch 96, total_steps 2000)\n",
            "End of epoch 96 / 200 \t Time Taken: 24 sec\n",
            "End of epoch 97 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 98 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 99 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 100, iters: 21, time: 0.918) G_GAN: 0.484 G_GAN_Feat: 4.144 G_VGG: 5.756 D_real: 0.169 D_fake: 0.667 \n",
            "End of epoch 100 / 200 \t Time Taken: 19 sec\n",
            "saving the model at the end of epoch 100, iters 2100\n",
            "End of epoch 101 / 200 \t Time Taken: 20 sec\n",
            "End of epoch 102 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 103 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 104 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 105, iters: 16, time: 0.915) G_GAN: 0.430 G_GAN_Feat: 3.298 G_VGG: 4.044 D_real: 0.263 D_fake: 0.696 \n",
            "End of epoch 105 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 106 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 107 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 108 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 109 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 110, iters: 11, time: 0.914) G_GAN: 1.591 G_GAN_Feat: 2.668 G_VGG: 4.019 D_real: 1.183 D_fake: 0.072 \n",
            "End of epoch 110 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 111 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 112 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 113 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 114 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 115, iters: 6, time: 0.915) G_GAN: 1.333 G_GAN_Feat: 3.206 G_VGG: 4.280 D_real: 0.961 D_fake: 0.118 \n",
            "End of epoch 115 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 116 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 117 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 118 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 119 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 120, iters: 1, time: 0.909) G_GAN: 0.421 G_GAN_Feat: 3.777 G_VGG: 5.076 D_real: 0.189 D_fake: 0.698 \n",
            "End of epoch 120 / 200 \t Time Taken: 19 sec\n",
            "saving the model at the end of epoch 120, iters 2520\n",
            "End of epoch 121 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 122 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 123 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 124, iters: 17, time: 0.915) G_GAN: 0.726 G_GAN_Feat: 2.861 G_VGG: 3.422 D_real: 0.534 D_fake: 0.400 \n",
            "End of epoch 124 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 125 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 126 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 127 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 128 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 129, iters: 12, time: 0.917) G_GAN: 0.926 G_GAN_Feat: 1.279 G_VGG: 3.255 D_real: 0.805 D_fake: 0.282 \n",
            "End of epoch 129 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 130 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 131 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 132 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 133 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 134, iters: 7, time: 0.915) G_GAN: 0.395 G_GAN_Feat: 1.507 G_VGG: 3.855 D_real: 0.334 D_fake: 0.647 \n",
            "End of epoch 134 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 135 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 136 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 137 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 138 / 200 \t Time Taken: 19 sec\n",
            "(epoch: 139, iters: 2, time: 0.915) G_GAN: 0.947 G_GAN_Feat: 1.379 G_VGG: 3.654 D_real: 0.809 D_fake: 0.352 \n",
            "End of epoch 139 / 200 \t Time Taken: 19 sec\n",
            "End of epoch 140 / 200 \t Time Taken: 19 sec\n",
            "saving the model at the end of epoch 140, iters 2940\n",
            "End of epoch 141 / 200 \t Time Taken: 23 sec\n",
            "update learning rate: 0.000200 -> 0.000197\n",
            "End of epoch 142 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000197 -> 0.000193\n",
            "(epoch: 143, iters: 18, time: 0.916) G_GAN: 0.762 G_GAN_Feat: 1.098 G_VGG: 2.924 D_real: 0.638 D_fake: 0.355 \n",
            "saving the latest model (epoch 143, total_steps 3000)\n",
            "End of epoch 143 / 200 \t Time Taken: 24 sec\n",
            "update learning rate: 0.000193 -> 0.000190\n",
            "End of epoch 144 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000190 -> 0.000187\n",
            "End of epoch 145 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000187 -> 0.000183\n",
            "End of epoch 146 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000183 -> 0.000180\n",
            "End of epoch 147 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000180 -> 0.000177\n",
            "(epoch: 148, iters: 13, time: 0.906) G_GAN: 0.464 G_GAN_Feat: 0.852 G_VGG: 1.988 D_real: 0.411 D_fake: 0.557 \n",
            "End of epoch 148 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000177 -> 0.000173\n",
            "End of epoch 149 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000173 -> 0.000170\n",
            "End of epoch 150 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000170 -> 0.000167\n",
            "End of epoch 151 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000167 -> 0.000163\n",
            "End of epoch 152 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000163 -> 0.000160\n",
            "(epoch: 153, iters: 8, time: 0.916) G_GAN: 0.606 G_GAN_Feat: 0.984 G_VGG: 2.618 D_real: 0.547 D_fake: 0.429 \n",
            "End of epoch 153 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000160 -> 0.000157\n",
            "End of epoch 154 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000157 -> 0.000153\n",
            "End of epoch 155 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000153 -> 0.000150\n",
            "End of epoch 156 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000150 -> 0.000147\n",
            "End of epoch 157 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000147 -> 0.000143\n",
            "(epoch: 158, iters: 3, time: 0.912) G_GAN: 0.776 G_GAN_Feat: 1.353 G_VGG: 3.462 D_real: 0.601 D_fake: 0.371 \n",
            "End of epoch 158 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000143 -> 0.000140\n",
            "End of epoch 159 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000140 -> 0.000137\n",
            "End of epoch 160 / 200 \t Time Taken: 19 sec\n",
            "saving the model at the end of epoch 160, iters 3360\n",
            "update learning rate: 0.000137 -> 0.000133\n",
            "End of epoch 161 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000133 -> 0.000130\n",
            "(epoch: 162, iters: 19, time: 0.916) G_GAN: 0.440 G_GAN_Feat: 0.630 G_VGG: 1.566 D_real: 0.403 D_fake: 0.588 \n",
            "End of epoch 162 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000130 -> 0.000127\n",
            "End of epoch 163 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000127 -> 0.000123\n",
            "End of epoch 164 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000123 -> 0.000120\n",
            "End of epoch 165 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000120 -> 0.000117\n",
            "End of epoch 166 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000117 -> 0.000113\n",
            "(epoch: 167, iters: 14, time: 0.916) G_GAN: 0.496 G_GAN_Feat: 0.873 G_VGG: 1.686 D_real: 0.401 D_fake: 0.530 \n",
            "End of epoch 167 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000113 -> 0.000110\n",
            "End of epoch 168 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000110 -> 0.000107\n",
            "End of epoch 169 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000107 -> 0.000103\n",
            "End of epoch 170 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000103 -> 0.000100\n",
            "End of epoch 171 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000100 -> 0.000097\n",
            "(epoch: 172, iters: 9, time: 0.916) G_GAN: 0.721 G_GAN_Feat: 0.814 G_VGG: 2.010 D_real: 0.635 D_fake: 0.358 \n",
            "End of epoch 172 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000097 -> 0.000093\n",
            "End of epoch 173 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000093 -> 0.000090\n",
            "End of epoch 174 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000090 -> 0.000087\n",
            "End of epoch 175 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000087 -> 0.000083\n",
            "End of epoch 176 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000083 -> 0.000080\n",
            "(epoch: 177, iters: 4, time: 0.919) G_GAN: 0.473 G_GAN_Feat: 0.966 G_VGG: 2.001 D_real: 0.380 D_fake: 0.542 \n",
            "End of epoch 177 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000080 -> 0.000077\n",
            "End of epoch 178 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000077 -> 0.000073\n",
            "End of epoch 179 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000073 -> 0.000070\n",
            "End of epoch 180 / 200 \t Time Taken: 19 sec\n",
            "saving the model at the end of epoch 180, iters 3780\n",
            "update learning rate: 0.000070 -> 0.000067\n",
            "(epoch: 181, iters: 20, time: 0.915) G_GAN: 0.677 G_GAN_Feat: 1.025 G_VGG: 2.315 D_real: 0.536 D_fake: 0.380 \n",
            "End of epoch 181 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000067 -> 0.000063\n",
            "End of epoch 182 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000063 -> 0.000060\n",
            "End of epoch 183 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000060 -> 0.000057\n",
            "End of epoch 184 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000057 -> 0.000053\n",
            "End of epoch 185 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000053 -> 0.000050\n",
            "(epoch: 186, iters: 15, time: 0.914) G_GAN: 0.741 G_GAN_Feat: 0.860 G_VGG: 1.939 D_real: 0.581 D_fake: 0.351 \n",
            "End of epoch 186 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000050 -> 0.000047\n",
            "End of epoch 187 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000047 -> 0.000043\n",
            "End of epoch 188 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000043 -> 0.000040\n",
            "End of epoch 189 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000040 -> 0.000037\n",
            "End of epoch 190 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000037 -> 0.000033\n",
            "(epoch: 191, iters: 10, time: 0.913) G_GAN: 0.480 G_GAN_Feat: 0.931 G_VGG: 1.836 D_real: 0.368 D_fake: 0.533 \n",
            "saving the latest model (epoch 191, total_steps 4000)\n",
            "End of epoch 191 / 200 \t Time Taken: 26 sec\n",
            "update learning rate: 0.000033 -> 0.000030\n",
            "End of epoch 192 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000030 -> 0.000027\n",
            "End of epoch 193 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000027 -> 0.000023\n",
            "End of epoch 194 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000023 -> 0.000020\n",
            "End of epoch 195 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000020 -> 0.000017\n",
            "(epoch: 196, iters: 5, time: 0.915) G_GAN: 0.529 G_GAN_Feat: 0.822 G_VGG: 1.636 D_real: 0.392 D_fake: 0.481 \n",
            "End of epoch 196 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000017 -> 0.000013\n",
            "End of epoch 197 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000013 -> 0.000010\n",
            "End of epoch 198 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000010 -> 0.000007\n",
            "End of epoch 199 / 200 \t Time Taken: 19 sec\n",
            "update learning rate: 0.000007 -> 0.000003\n",
            "(epoch: 200, iters: 21, time: 0.914) G_GAN: 0.527 G_GAN_Feat: 0.435 G_VGG: 0.843 D_real: 0.516 D_fake: 0.480 \n",
            "End of epoch 200 / 200 \t Time Taken: 19 sec\n",
            "saving the model at the end of epoch 200, iters 4200\n",
            "update learning rate: 0.000003 -> 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy5clSvyIxn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5841078d-9dc1-45c7-a575-6f55d852e812"
      },
      "source": [
        "%run test.py --name force --dataroot ./datasets/force/ --no_instance --label_nc 0 --loadSize 1024 --fineSize 1024 --resize_or_crop none --how_many 2000"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "dataroot: ./datasets/force/\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 1024\n",
            "gpu_ids: [0]\n",
            "how_many: 2000\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "max_dataset_size: inf\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: force\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./results/\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "---------- Networks initialized -------------\n",
            "model [Pix2PixHDModel] was created\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/pix2pixHD/models/pix2pixHD_model.py:112: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  input_label = Variable(input_label, volatile=infer)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "process image... ['./datasets/force/test_label/005-1i.jpg']\n",
            "process image... ['./datasets/force/test_label/005-2i.jpg']\n",
            "process image... ['./datasets/force/test_label/010-1i.jpg']\n",
            "process image... ['./datasets/force/test_label/010-2i.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}